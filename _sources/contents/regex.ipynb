{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import graphviz\n",
    "import automathon\n",
    "from automathon import DFA, NFA\n",
    "from myst_nb import glue\n",
    "from IPython.display import display, SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:regex)=\n",
    "\n",
    "# 正規表現の基礎\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何らかのテキストが与えられた時、その中に、含まれる文字列を検索することは、テキストエディタの基本的な機能となっている。このような検索機能においては、単純に`\"Hello\"`という文字が含まれるか、という単純なものではなく、`\"H\"`から始まる5文字の単語を検索したい、といったような少々曖昧な検索を行いたい場合もあるだろう。\n",
    "\n",
    "このような場合に使うことができる**検索パターンの表現**の一種が**正規表現**である。本節では、正規表現をPythonプログラムの中で使用する方法について学ぶ。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規表現とは？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**正規表現** (regular expression)とは、少し複雑な言い方をすれば**正規言語**に基づく文字表現のことを指す。正規表現の考え方は元々、神経科学分野で発生したもので、それを数学者のStephen Kleeneが**正規集合**として明確な定義を与えた。\n",
    "\n",
    "その後、1968年になってKen Thompsonが自身の論文の中で、彼が作成したUNIX上のテキストエディタである**qed**に実装された正規表現を実現するコンパイラの仕組みについて紹介した。これが、UNIX上の文字列検索システムである**grep** (global regular expression)や**sed**へと発展した {cite}`shinya2015regex`。\n",
    "\n",
    "現在では、多くのテキストエディタで正規表現を用いた文字列検索を使用できるほか、Pythonを含むほとんどのプログラミング言語で正規表現を用いるためのライブラリが用意されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythonにおいては標準ライブラリの`re`を通して正規表現を用いることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用方法の一例として、以下に`\"Hello, world!\"`という文字列の中に`\"Hello\"`という文字列が含まれるかどうかを調べるプログラムを示す (これだけなら正規表現を使う必要はないが...)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world!\"\n",
    "pat = re.compile(r\"Hello\")\n",
    "if pat.search(text):\n",
    "    print(\"Match\")\n",
    "else:\n",
    "    print(\"Not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw文字列リテラル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規表現を定義する場合、Vim等のテキストエディタやPerl等の他のプログラミング言語では`/.../`のようにスラッシュで区切られた文字列(=**正規表現リテラル**)を用いる。一方、Pythonには正規表現リテラルに類する概念はなく、通常の文字列の他、**raw文字列リテラル**によって定義することが推奨されている。\n",
    "\n",
    "raw文字列リテラルは`r\"...\"`のように、クオーテーションの前に`r`を伏した文字列で定義される。まずは通常の文字列との違いを確認するために、以下の例を見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: '\\'\n",
      "2: '\t'\n",
      "3: '\\\t'\n",
      "3: '\\\\t'\n"
     ]
    }
   ],
   "source": [
    "print(\"1: '\\\\'\")\n",
    "print(\"2: '\\t'\")\n",
    "print(\"3: '\\\\\\t'\")\n",
    "print(\"3: '\\\\\\\\t'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例から分かるように、バックスラッシュを入力するには文字列中で`\"\\\\\"`のように表記する必要があり、単体のバックスラッシュである`\"\\\"`はタブ文字 (`\\t`)や改行文字(`\\n`)のような特殊文字を表すのに使われている。では、これを正規表現に用いようとすると何が起こるだろうか？以下のバックスラッシュとタブ文字を含む文字列に正規表現を使ってみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\\is\t\ta\\table\n"
     ]
    }
   ],
   "source": [
    "text = \"this\\\\is\\t\\ta\\\\table\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**文字列リテラルを使う場合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 8), match='\\t'>\n",
      "<re.Match object; span=(7, 8), match='\\t'>\n",
      "<re.Match object; span=(10, 12), match='\\\\t'>\n"
     ]
    }
   ],
   "source": [
    "# 文字列リテラルの場合\n",
    "p = re.compile(\"\\t\")  # タブ文字\n",
    "print(p.search(text))  # -> タブ文字とマッチ\n",
    "p = re.compile(\"\\\\t\")  # これもタブ文字\n",
    "print(p.search(text))  # -> タブ文字とマッチ\n",
    "p = re.compile(\"\\\\\\\\t\")  # \"\\\"と\"t\"の2文字\n",
    "print(p.search(text))  # -> \"\\\\t\"とマッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この結果をみると、少々、予想と外れているように見えるかもしれない。特に、2番目の結果にある`\"\\\\t\"`がタブ文字とマッチしているのは不可解に見える。しかし、これは文字列の評価と正規表現の評価が二重で行なわれることに起因する現象である。\n",
    "\n",
    "まず、`re.compile`の引数に文字列として`\"\\\\t\"`が与えられると、これが文字列として`\"\\\"`と`\"t\"`の2文字である、と認識される。その後、この2文字が正規表現の評価に使われるので、`compile`関数は`\"\\t\"`という2文字をタブ文字として解釈する。\n",
    "\n",
    "このような、文字列評価の二重性を正しく理解していれば、上記の結果は予想の範囲内ではあるものの、より複雑な正規表現を書く場合には、特にバックスラッシュを多用することになるため、混乱が起きやすい。以上の理由から、Pythonでは、正規表現のコンパイル時にはraw文字列リテラルを用いることが強く推奨されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw文字列リテラルを使う場合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(7, 8), match='\\t'>\n",
      "<re.Match object; span=(10, 12), match='\\\\t'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# raw文字列リテラルの場合\n",
    "p = re.compile(r\"\\t\")  # タブ文字\n",
    "print(p.search(text))  # -> タブ文字とマッチ\n",
    "p = re.compile(r\"\\\\t\")  # \"\\\"と\"t\"の2文字\n",
    "print(p.search(text))  # -> \"\\\\t\"とマッチ\n",
    "p = re.compile(r\"\\\\\\\\t\")  # \"\\\"と”\\\"と\"t\"の3文字\n",
    "print(p.search(text))  # マッチしない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw文字列リテラルを用いると、正規表現の`re.compile`関数に文字列がそのまま評価されるため、バックスラッシュの解釈がより単純になっていることが分かる。従って、特段の理由がない限りはraw文字列リテラルを用いて正規表現パターンを定義するのが良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規表現の基本的な使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規表現のパターン文字列である`pat`には指定した文字列の中に正規表現とマッチする文字列が存在するかを調べる`search`の他にも\n",
    "\n",
    "- 文字列が正規表現と完全にマッチするかを調べる `fullmatch`\n",
    "- マッチする全ての文字列を取り出す `findall`\n",
    "- マッチする文字列を別の文字列に置き換える `sub`\n",
    "- マッチする文字列で文章を区切る `split`\n",
    "\n",
    "などのメソッドが用意されている。このそれぞれについて、簡単に使い方を見てみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`fullmatch`の使用例**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not match\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world!\"\n",
    "pat = re.compile(r\"Hello\")\n",
    "if pat.fullmatch(text):\n",
    "    print(\"Match\")\n",
    "else:\n",
    "    print(\"Not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`findall`の使用例**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 \"Hello\"s.\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world! Hello, Japan!\"\n",
    "pat = re.compile(r\"Hello\")\n",
    "n_match = len(pat.findall(text))\n",
    "print(f'There are {n_match:d} \"Hello\"s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`sub`の使用例**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, world! Bonjour, Japan!\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world! Hello, Japan!\"\n",
    "pat = re.compile(r\"Hello\")\n",
    "res = pat.sub(\"Bonjour\", text)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`split`の使い方**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', 'world!', 'Hello,', 'Japan!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world! Hello, Japan!\"\n",
    "pat = re.compile(r\" \")\n",
    "res = pat.split(text)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 正規表現の基本\n",
    ":class: note\n",
    "\n",
    "- 正規表現は特定の文字パターンに合致する文字列を探すのに用いる\n",
    "- Pythonにおいては標準ライブラリの`re`を用いる\n",
    "- 正規表現を定義するときは、raw文字列リテラルを用いる\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規表現のシンタックス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの例では単純に何らかの文字列が、別の文字列に含まれるかどうかを調べてきたが、Pythonであれば、このような動作は、単純に\n",
    "\n",
    "```python\n",
    "text = \"Hello, world!\"\n",
    "if \"Hello\" in text:\n",
    "    print(\"Match\")\n",
    "else:\n",
    "    print(\"Not match\")\n",
    "```\n",
    "\n",
    "のように書けば十分である。\n",
    "\n",
    "正規表現の有効性は、特定の文字列を探すことではなく、より複雑なパターンにマッチする文字列を探すことにある。以下では、正規表現パターンを定義するためのシンタックスについて基本的なものをいくつか紹介する。一方で、正規表現のシンタックスは非常に多岐に渡るため、より詳しく知りたい読者はPythonの[公式ドキュメント](https://docs.python.org/ja/3/library/re.html)を参照すると良い。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 何らかの1文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何らかの1文字が存在することを表したい場合には、`a.c`のように`.`を用いる。この正規表現は例えば`abc`や`adc`など、`.`の部分に何らかの1文字がはいるような文字列とはマッチするが、`abdc`のように`.`に対応する場所に2文字以上の文字が存在する場合とはマッチしない。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('a.c')\n",
      "abc : <re.Match object; span=(0, 3), match='abc'>\n",
      "adc : <re.Match object; span=(0, 3), match='adc'>\n",
      "abdc : None\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"a.c\")\n",
    "print(\"PATTERN:\", pat)\n",
    "print(text := \"abc\", \":\", pat.fullmatch(text))\n",
    "print(text := \"adc\", \":\", pat.fullmatch(text))\n",
    "print(text := \"abdc\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字の繰り返し\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何らかの文字が繰り返しているかを調べたい場合には、文字の繰り返しを表す`*`あるいは`+`を用いる。例えば、`aaabcccc`のような文字列とマッチさせたい場合`a+bc+`のように繰り返したい文字の後に`+`あるいは`*`をつける。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('a+bc+')\n",
      "aaabcccc : <re.Match object; span=(0, 8), match='aaabcccc'>\n",
      "aabbcc : None\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"a+bc+\")\n",
    "print(\"PATTERN:\", pat)\n",
    "\n",
    "print(text := \"aaabcccc\", \":\", pat.fullmatch(text))\n",
    "print(text := \"aabbcc\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} 「*」と「+」の違い\n",
    ":class: tip\n",
    "\n",
    "文字の繰り返しを表す`+`と`*`は、その繰り返し回数の見方に違いがある。\n",
    "\n",
    "`+`は直前の文字が**1回以上繰り返す**場合にのみマッチするのに対し、`*`は**0回以上の繰り返し**にもマッチする。従って、\n",
    "\n",
    "- `ab+`というパターンは`a`にはマッチせず、`ab`にはマッチする\n",
    "- `ab*`というパターンは`a`にマッチし、なおかつ`ab`にもマッチする\n",
    "\n",
    "という動作の違いがある。これらの違いについては、ぜひ読者自身で確認してみてほしい。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繰り返し回数の制限"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`*`や`+`は繰り返し回数が無制限であったが、回数を制限した繰り返しを定義することもできる。例えば、`aabb`は検出したいが、`aaabb`のように`a`が3回以上繰り返す場合は検出したくない、という場合、繰り返し回数を2回以下に制限して、`a{1,2}b+`のような文字パターンを定義することができる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('a{1,2}b+')\n",
      "aabb : <re.Match object; span=(0, 4), match='aabb'>\n",
      "aaabb : None\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"a{1,2}b+\")\n",
    "print(\"PATTERN:\", pat)\n",
    "print(text := \"aabb\", \":\", pat.fullmatch(text))\n",
    "print(text := \"aaabb\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複数の文字列のいずれか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いては、複数の文字列のいずれかにマッチする正規表現を紹介する。例えば、`\"Hello\"`と`\"Bonjour\"`のいずれかにマッチする正規表現は、これらの文字列を`|`で結んで`Hello|Bonjour`のように定義できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN re.compile('Hello|Bonjour')\n",
      "Hello, world! : <re.Match object; span=(0, 5), match='Hello'>\n",
      "Bonjour, le monde! : <re.Match object; span=(0, 7), match='Bonjour'>\n",
      "Hallo, welt! : None\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"Hello|Bonjour\")\n",
    "print(\"PATTERN\", pat)\n",
    "print(text := \"Hello, world!\", \":\", pat.search(text))\n",
    "print(text := \"Bonjour, le monde!\", \":\", pat.search(text))\n",
    "print(text := \"Hallo, welt!\", \":\", pat.search(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この表現は3つ以上の文字列のいずれかにマッチさせたい場合にも使用することができ、その場合は`Hello|Bonjour|Hallo`のように複数の文字列を`|`で結べば良い。\n",
    "\n",
    "しかし、`|`は、正規表現を処理するアルゴリズムの性質上、少々計算に時間がかかる(現実的な長さの文字列ならあまり気にしなくて良いが...)ため、他の正規表現を用いて同様の表現を定義できないか考えることが大事である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字クラス\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの例では、`+`や`*`といった文字の繰り返しは直前の1文字にしか適用していなかったが、**文字クラス**用いることでクラス内の任意の文字の繰り返しを定義することができる。例えば、a, b, cの三文字だけで構成された文字かどうかを調べたい場合`[abc]+`のように繰り返しに含めたい文字を`[...]`の内側に入れることで文字クラスを定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aabbccaa : <re.Match object; span=(0, 8), match='aabbccaa'>\n",
      "aaddccaa : None\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"[abc]+\")\n",
    "print(text := \"aabbccaa\", \":\", pat.fullmatch(text))\n",
    "print(text := \"aaddccaa\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、Python の正規表現ではUnicodeの番号が連続する文字種を用いて範囲指定できるため、例えば`[a-z]`のように書くと、小文字のアルファベット全てにマッチする文字クラスを定義することができる。\n",
    "\n",
    "この場合、`[a-z]`のように書くと、**小文字アルファベット1文字**にマッチする文字クラスが定義され、これに繰り返しを表す`*`や`+`を追加し、`[a-z]+`のように書くことで、小文字アルファベットのみからなる文字列を検索することができる。\n",
    "\n",
    "文字クラス内の範囲指定は複数のものを連続して書けるため、大文字小文字の全てのアルファベットにマッチさせたい場合は`[a-zA-Z]`と書けば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('[a-zA-Z]+')\n",
      "Hello : <re.Match object; span=(0, 5), match='Hello'>\n",
      "Hi? : None\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"[a-zA-Z]+\")\n",
    "print(\"PATTERN:\", pat)\n",
    "print(text := \"Hello\", \":\", pat.fullmatch(text))\n",
    "print(text := \"Hi?\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**除外文字クラス**\n",
    "\n",
    "文字クラスは、**そのクラスに含まれない全ての文字**に対してマッチさせることもできる。このような除外文字のクラスを定義するには、文字クラスの先頭に`^`を付与して`[^a-z]`とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('[^a-z]+')\n",
      "Hello : None\n",
      "HELLO : <re.Match object; span=(0, 5), match='HELLO'>\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"[^a-z]+\")\n",
    "print(\"PATTERN:\", pat)\n",
    "print(text := \"Hello\", \":\", pat.fullmatch(text))\n",
    "print(text := \"HELLO\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接頭辞、接尾辞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列の先頭から特定のパターンが出現するかどうかを調べるには、正規表現の最初に`^`を追加する。反対に、文字列の末尾に特定のパターンが出現するかどうかを調べるには、正規表現の最後に`$`を追加する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('^[A-Z]+.*')\n",
      "Hello : <re.Match object; span=(0, 5), match='Hello'>\n",
      "hello : None\n"
     ]
    }
   ],
   "source": [
    "# 接頭辞のチェック\n",
    "pat = re.compile(\"^[A-Z]+.*\")\n",
    "print(\"PATTERN:\", pat)\n",
    "print(text := \"Hello\", \":\", pat.fullmatch(text))\n",
    "print(text := \"hello\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN: re.compile('.*[a-z]+$')\n",
      "Hello : <re.Match object; span=(0, 5), match='Hello'>\n",
      "HELLO : None\n"
     ]
    }
   ],
   "source": [
    "# 接尾辞のチェック\n",
    "pat = re.compile(\".*[a-z]+$\")\n",
    "print(\"PATTERN:\", pat)\n",
    "print(text := \"Hello\", \":\", pat.fullmatch(text))\n",
    "print(text := \"HELLO\", \":\", pat.fullmatch(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最短マッチ、最長マッチ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字の繰り返しを含む文字列を検索する場合、初期動作としては、**マッチする文字列のうち最長ものが検出される**。\n",
    "\n",
    "例えば、`t`から始まって`e`終わるような大文字・小文字アルファベットからなる単語を検索したい場合を考えよう。この場合、正規表現のパターンを作成すると以下のようになるだろう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(\"t.+e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この時、以下のような文字列が与えられたとする。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I take a cup of tea.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この文字列に対して、先ほどの正規表現パターンを検索してみると、次のような結果となる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(2, 18), match='take a cup of te'>\n"
     ]
    }
   ],
   "source": [
    "print(pat.search(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは**tから始まりeで終わる最長の文字列**を検出しているが、本来、検出したい文字列は通常`take`だろう。このように、マッチするパターンのうち、より短いパターンを検出したい場合には、繰り返しを表す`+`や`*`の後に`?`を付け加えて正規表現を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(2, 6), match='take'>\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(\"t.+?e\")\n",
    "print(pat.search(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メタ文字\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラミング言語によって若干の違いはあるが、正規表現には事前に定義された**メタ文字**が用意されている。例えば、`\\s`というメタ文字は、半角スペース (` `)、タブ (`\\t`)、キャリッジリターン (`\\r`)、改ページ (`\\f`)、垂直タブ (`\\v`)の全てにマッチする。\n",
    "\n",
    "このようなメタ文字は、文字セットによって代替することも可能だが、数字やスペース記号は頻繁に用いる文字セットであり、メタ文字を使う方が、正規表現パターンをより短い文字列で表せるという点で優れている。\n",
    "\n",
    "| メタ文字 | 等価な正規表現   | 説明                                               |\n",
    "| :------- | :--------------- | :------------------------------------------------- |\n",
    "| `\\d`     | `[0-9]`          | 全ての数字にマッチする                             |\n",
    "| `\\D`     | `[^0-9]`         | 数字以外の全ての文字にマッチする                   |\n",
    "| `\\s`     | `[ \\t\\n\\r\\f\\v]`  | 全てのスペース記号とマッチする                     |\n",
    "| `\\S`     | `[^ \\t\\n\\r\\f\\v]` | 全てのスペース記号でない文字とマッチする           |\n",
    "| `\\w`     | `[a-zA-Z0-9_]`   | 全ての英数字とアンダースコアとマッチする           |\n",
    "| `\\W`     | `[^a-zA-Z0-9_]`  | 英数字とアンダースコア以外の全ての文字とマッチする |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一例として、連続するスペースやタブ文字で文字列を分解するコードは頻出である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'world!', 'Hello,', 'Japan!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello  world!\\tHello,       Japan!\"\n",
    "pat = re.compile(r\"\\s+\")\n",
    "print(pat.split(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊文字のエスケープ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の通り、正規表現では、`*`や`+`の他、`[]`や`{}`が、特殊な意味を持つことが分かる。このような特殊文字を文字列から検索するためには、バックスラッシュにより**エスケープ**する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 3), match='1+1'>\n"
     ]
    }
   ],
   "source": [
    "text = \"1+1=2\"\n",
    "\n",
    "# エスケープなし\n",
    "pat = re.compile(r\"[0-9]++[0-9]+\")\n",
    "print(pat.search(text))  # マッチしない\n",
    "\n",
    "# エスケープあり\n",
    "pat = re.compile(r\"[0-9]+\\+[0-9]+\")\n",
    "print(pat.search(text))  # マッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各文字がエスケープを必要とするかどうかは文字をエスケープした文字(=`re.escape`を使う)と元の文字が同じになるかどうかをチェックすれば良い。エスケープが必要な文字のリストは以下の通り。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# $ & ( ) \n",
      "* + - . ? \n",
      "[ \\ ] ^ { \n",
      "| } ~ "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(33, 128):\n",
    "    if (c := chr(i)) != re.escape(c):\n",
    "        print(c, end=\" \")\n",
    "        cnt += 1\n",
    "        if cnt % 5 == 0:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 正規表現のシンタックス\n",
    ":class: note\n",
    "- 正規表現には複雑な文字パターンを定義するために様々なシンタックスが存在する\n",
    "- 文字クラスを用いると、複数の文字のいずれか一つを表すことができる\n",
    "- 文字クラスと繰り返し記号(`*`や`+`)を用いると、特定の文字種のみからなる文字列を検索できる\n",
    "- 正規表現の定義に用いられる特殊文字を検索したい場合にはエスケープをする必要がある\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非決定性有限オートマトン\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在、正規表現を処理するための仕組みには大きく分けて**非決定性有限オートマトン** (NFA, non-deterministic finite automaton)に基づく**NFA型**と、**バックトラッキング法**に基づく**VM型** (VMはVirtual Machineの略)の2つがある。現在、多くの言語では、表現の柔軟性から後者のVM型の正規表現解析法が使われており、Pythonの正規表現もVM型を採用している {cite}`felix2014understanding`。\n",
    "\n",
    "その一方、前述のThompsonによる正規表現はNFA型を採用していたこともあり、正規表現を理解する上でNFAの理解は避けては通れない。ここでは、NFAを用いた正規表現の解析法について、簡単に紹介する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有限オートマトン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**オートマトン**とは、計算機を単純化したモデルの一つであり、**状態**と、状態遷移を表す**規則**からなる。オートマトンは、この状態と規則を元に入力の文字列を読み取る動作を定義する。\n",
    "\n",
    "例えば、aとbからなる*何らかの*文字列を読み取るオートマトンは次のように定義される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "q = {\"q0\", \"q1\"}\n",
    "sigma = {\"a\", \"b\"}\n",
    "delta = {\"q0\": {\"a\": \"q1\"}, \"q1\": {\"b\": \"q0\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"217pt\" height=\"46pt\" viewBox=\"0.00 0.00 216.80 46.20\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 42.2)\">\n",
       "<title>dfa</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-42.2 212.8,-42.2 212.8,4 -4,4\"/>\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title/>\n",
       "</g>\n",
       "<!-- q0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"109.76\" cy=\"-19.43\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.76\" y=\"-13.26\" font-family=\"Times,serif\" font-size=\"14.00\">q0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54,-19.43C62.05,-19.43 70.99,-19.43 79.26,-19.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.22,-22.93 89.22,-19.43 79.22,-15.93 79.22,-22.93\"/>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"190.04\" cy=\"-19.43\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.04\" y=\"-13.26\" font-family=\"Times,serif\" font-size=\"14.00\">q1</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q1-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.9,-8.26C166.82,-3.2 156.37,1.18 146.53,-1.18 143.11,-2 139.66,-3.21 136.31,-4.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.97,-1.37 127.52,-8.9 138.04,-7.66 134.97,-1.37\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.9\" y=\"-2.38\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0-&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.92,-19.43C138.01,-19.43 149.24,-19.43 159.53,-19.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.47,-22.93 169.47,-19.43 159.47,-15.93 159.47,-22.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.9\" y=\"-20.38\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "auto01"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_state = \"q0\"\n",
    "accept_state = {}\n",
    "\n",
    "automata = automathon.DFA(q, sigma, delta, initial_state, accept_state)\n",
    "automata.view(file_name=\"dfa\")\n",
    "\n",
    "g = graphviz.Source.from_file(\"dfa.gv\")\n",
    "g.render(format=\"svg\")\n",
    "with open(\"dfa.gv.svg\", \"rb\") as f:\n",
    "    svg = SVG(f.read())\n",
    "\n",
    "glue(\"auto01\", svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{glue:figure} auto01\n",
    ":name: auto01\n",
    ":width: 50%\n",
    "\n",
    "有限オートマトンの例\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このオートマトンは`q0`と`q1`の2つの状態を持ち、文字`a`あるいは`b`を読み取ると、二つの状態の間で遷移が起こる。初期状態は`q0`であり、このオートマトンは`ababa...`のような`a`と`b`が交互に現れるような文字列を読み取る。\n",
    "\n",
    "オートマトンには受理状態と呼ばれる最終状態を定義することができ、以下のように二重丸で示した状態を受理状態であると見なす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"225pt\" height=\"54pt\" viewBox=\"0.00 0.00 224.80 53.53\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 49.53)\">\n",
       "<title>dfa</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-49.53 220.8,-49.53 220.8,4 -4,4\"/>\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title/>\n",
       "</g>\n",
       "<!-- q0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"109.76\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.76\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54,-22.76C62.05,-22.76 70.99,-22.76 79.26,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.22,-26.26 89.22,-22.76 79.22,-19.26 79.22,-26.26\"/>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"194.04\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"194.04\" cy=\"-22.76\" rx=\"22.76\" ry=\"22.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.04\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q1</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q1-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.86,-10.01C166.42,-5.57 156.14,-2.2 146.53,-4.51 143.11,-5.33 139.66,-6.54 136.31,-7.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.97,-4.7 127.52,-12.23 138.04,-10.99 134.97,-4.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.9\" y=\"-5.71\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0-&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.02,-22.76C138.03,-22.76 149.19,-22.76 159.66,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.51,-26.26 169.51,-22.76 159.51,-19.26 159.51,-26.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.9\" y=\"-23.71\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "auto02"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_state = \"q0\"\n",
    "accept_state = {\"q1\"}\n",
    "\n",
    "automata = automathon.DFA(q, sigma, delta, initial_state, accept_state)\n",
    "automata.view(file_name=\"dfa\")\n",
    "\n",
    "g = graphviz.Source.from_file(\"dfa.gv\")\n",
    "g.render(format=\"svg\")\n",
    "with open(\"dfa.gv.svg\", \"rb\") as f:\n",
    "    svg = SVG(f.read())\n",
    "\n",
    "glue(\"auto02\", svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{glue:figure} auto02\n",
    ":name: auto02\n",
    ":width: 50%\n",
    "\n",
    "受理状態を持つ有限オートマトン\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例では状態`q1`が受理状態であり、文字列の終端まで読み取った時に状態が`q1`であれば文字列が受理される。従って、このオートマトンでは`ababab`という文字列は受理されるが、`ababa`という文字列は棄却される。\n",
    "\n",
    "オートマトンのうち状態の数が有限であるものを特に**有限オートマトン**と呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定性と非決定性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{ref}`先ほどの例<auto02>`に示したオートマトンは入力が与えられると決定論的に文字列が読み取られていくという特徴があり、入力文字列に対して状態遷移が一意に決まる。このような動作が決定的な有限オートマトンのことを**決定性有限オートマトン** (DFA, deterministic finite automaton)と呼ぶ。\n",
    "\n",
    "DFAのより複雑な例として、`a`と`b`だけからなる文字列(今回は`a`と`b`が繰り返しても良い)を受理するとDFAは以下のように表せる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"233pt\" height=\"86pt\" viewBox=\"0.00 0.00 232.80 85.78\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 81.78)\">\n",
       "<title>dfa</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-81.78 228.8,-81.78 228.8,4 -4,4\"/>\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title/>\n",
       "</g>\n",
       "<!-- q0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"113.76\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"113.76\" cy=\"-22.76\" rx=\"22.76\" ry=\"22.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.76\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.89,-22.76C61.9,-22.76 70.84,-22.76 79.28,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.23,-26.26 89.23,-22.76 79.23,-19.26 79.23,-26.26\"/>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"202.04\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"202.04\" cy=\"-22.76\" rx=\"22.76\" ry=\"22.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"202.04\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q1</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>q1-&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.96,-44.15C192.97,-54.44 195.66,-63.53 202.04,-63.53 205.83,-63.53 208.31,-60.32 209.5,-55.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.99,-55.84 210.03,-45.67 206,-55.46 212.99,-55.84\"/>\n",
       "<text text-anchor=\"middle\" x=\"202.04\" y=\"-64.48\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>q1-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.9,-10.2C174.47,-5.79 164.19,-2.4 154.53,-4.51 151.15,-5.25 147.71,-6.3 144.35,-7.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143.24,-4.21 135.39,-11.33 145.97,-10.65 143.24,-4.21\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.9\" y=\"-5.71\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q0-&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.98,-22.76C146.24,-22.76 157.19,-22.76 167.4,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.38,-26.26 177.38,-22.76 167.38,-19.26 167.38,-26.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.9\" y=\"-23.71\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.18,-44.57C105.35,-54.69 107.88,-63.53 113.76,-63.53 117.26,-63.53 119.57,-60.41 120.69,-55.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.17,-56.27 121.26,-46.08 117.18,-55.86 124.17,-56.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.76\" y=\"-64.48\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "auto03"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = {\"q0\", \"q1\"}\n",
    "sigma = {\"a\", \"b\"}\n",
    "delta = {\"q0\": {\"a\": \"q0\", \"b\": \"q1\"}, \"q1\": {\"a\": \"q0\", \"b\": \"q1\"}}\n",
    "\n",
    "initial_state = \"q0\"\n",
    "accept_state = {\"q0\", \"q1\"}\n",
    "\n",
    "automata = automathon.DFA(q, sigma, delta, initial_state, accept_state)\n",
    "automata.view(file_name=\"dfa\")\n",
    "\n",
    "g = graphviz.Source.from_file(\"dfa.gv\")\n",
    "g.render(format=\"svg\")\n",
    "with open(\"dfa.gv.svg\", \"rb\") as f:\n",
    "    svg = SVG(f.read())\n",
    "\n",
    "glue(\"auto03\", svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{glue:figure} auto03\n",
    ":name: auto03\n",
    ":width: 50%\n",
    "\n",
    "より複雑な決定性有限オートマトン\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方で、入力の文字列に対して、状態遷移が一意に定まらない有限オートマトンもあり、これを**非決定性有限オートマトン** (NFA, non-deterministic finite automaton)と呼ぶ。最も代表的な例は、後ろから何番目かに特定の文字が存在するかどうかを調べる有限オートマトンである。\n",
    "\n",
    "今、文字列が`a`と`b`の2文字から構成されていて、最後から3番目に`b`が存在するかどうかを調べる有限オートマトンを考える。この有限オートマトンは以下のように表現できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"405pt\" height=\"82pt\" viewBox=\"0.00 0.00 404.85 81.78\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 77.78)\">\n",
       "<title>dfa</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-77.78 400.85,-77.78 400.85,4 -4,4\"/>\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title/>\n",
       "</g>\n",
       "<!-- q0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"109.76\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.76\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54,-22.76C62.05,-22.76 70.99,-22.76 79.26,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.22,-26.26 89.22,-22.76 79.22,-19.26 79.22,-26.26\"/>\n",
       "</g>\n",
       "<!-- q3 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"374.09\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"374.09\" cy=\"-22.76\" rx=\"22.76\" ry=\"22.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"374.09\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q3</text>\n",
       "</g>\n",
       "<!-- q2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"280.06\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.06\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q2</text>\n",
       "</g>\n",
       "<!-- q2&#45;&gt;q3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>q2-&gt;q3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.24,-22.76C310.75,-22.76 325.98,-22.76 339.61,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"339.54,-26.26 349.54,-22.76 339.54,-19.26 339.54,-26.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"325.08\" y=\"-23.71\" font-family=\"Times,serif\" font-size=\"14.00\">a,b</text>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"190.04\" cy=\"-22.76\" rx=\"18.76\" ry=\"18.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.04\" y=\"-16.59\" font-family=\"Times,serif\" font-size=\"14.00\">q1</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>q1-&gt;q2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M209.28,-22.76C220.84,-22.76 236.08,-22.76 249.36,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.33,-26.26 259.33,-22.76 249.33,-19.26 249.33,-26.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.05\" y=\"-23.71\" font-family=\"Times,serif\" font-size=\"14.00\">a,b</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q0-&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.92,-22.76C138.01,-22.76 149.24,-22.76 159.53,-22.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.47,-26.26 169.47,-22.76 159.47,-19.26 159.47,-26.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.9\" y=\"-23.71\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0-&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.11,-40.54C101.87,-50.42 104.09,-59.53 109.76,-59.53 113.04,-59.53 115.17,-56.48 116.14,-52.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.64,-52.14 116.38,-42.05 112.64,-51.97 119.64,-52.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.76\" y=\"-60.48\" font-family=\"Times,serif\" font-size=\"14.00\">a,b</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "auto04"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = {\"q0\", \"q1\", \"q2\", \"q3\"}\n",
    "sigma = {\"a\", \"b\"}\n",
    "delta = {\n",
    "    \"q0\": {\n",
    "        \"a,b\": \"q0\",\n",
    "        \"b\": \"q1\"\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"a,b\": \"q2\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"a,b\": \"q3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "initial_state = \"q0\"\n",
    "accept_state = {\"q3\"}\n",
    "\n",
    "automata = automathon.DFA(q, sigma, delta, initial_state, accept_state)\n",
    "automata.view(file_name=\"dfa\")\n",
    "\n",
    "g = graphviz.Source.from_file(\"dfa.gv\")\n",
    "g.render(format=\"svg\")\n",
    "with open(\"dfa.gv.svg\", \"rb\") as f:\n",
    "    svg = SVG(f.read())\n",
    "\n",
    "glue(\"auto04\", svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{glue:figure} auto04\n",
    ":name: auto04\n",
    ":width: 90%\n",
    "\n",
    "非決定性有限オートマトンの例\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この有限オートマトンは、一度、文字`b`が読み取られて状態が`q1`に遷移すると、そこから`a`, `b`のいずれかの文字を2文字読み取って受理状態である`q3`に遷移する。従って、`b`という文字が後ろから3番目にある文字列が受理されることが分かる。\n",
    "\n",
    "この例で注目すべきは、上記の有限オートマトンが状態`q0`において文字`a`が与えられた時に、状態`q0`自身への遷移と状態`q1`への遷移が存在する、という点である。このように、特定の文字列に対して複数の遷移が存在するのが非決定性有限オートマトンの特徴である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規表現との関係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほどの{ref}`NFAの例<auto04>`のように、最後から3番目に文字`b`が存在するかどうかを調べる正規表現は`[ab]*b[ab][ab]`のように書ける。\n",
    "\n",
    "実際のところ、正規表現パターンのうち`|`と`*`だけを含むようなものは非決定性有限オートマトンと等価である。これは`a|b`のような正規表現が`a`あるいは`b`を読み取って自身以外の状態へと遷移する動作を、`a*`のような正規表現が文字`a`を読み取って自身へと遷移する動作を表すことを考えれば自然である。\n",
    "\n",
    "また、より複雑な正規表現も、実は`|`と`*`だけを使えば表すことができ、`a+`は`aa*`と等価であるし、`[ab]*`は`(a|b)*`と等価である。以上から、正規表現と非決定性有限オートマトンの等価性が伺える。\n",
    "\n",
    "しかし、ここまでの議論は演繹的な議論であり、より厳密に等価性を議論するには、数学的に有限オートマトンを定義する必要がある。詳細に興味のある読者は参考文献に挙げた資料を参照してみてほしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 正規表現と非決定性有限オートマトン\n",
    ":class: note\n",
    "\n",
    "- 現在の正規表現エンジンには非決定有限オートマトンに基づくNFA型とバックトラック法に基づくVM型がある\n",
    "- 有限オートマトンには決定性有限オートマトンと非決定性有限オートマトンがある\n",
    "- 決定性と非決定性は、特定の文字列が与えられた時の遷移先が一意に決まるか否かで決まる\n",
    "- 正規表現は非決定性有限オートマトンと等価なものとして定義できる\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## サブグループ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規表現でマッチした文字列の全体及び一部を取り出す方法に**サブグループ**を用いる方法がある。サブグループは正規表現内で括弧`(...)`を使うことで定義でき、その内部に記述した正規表現とマッチしたサブグループには、先頭から順に1から番号が振られる。\n",
    "\n",
    "サブグループに対応する文字列は`search`や`fullmatch`の戻り値である`Match`型の変数に対して、サブグループの番号を与えることで取得できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full: <a href=\"http://www.google.com\" alt=\"google\">Google</a>\n",
      "sub#1: http://www.google.com\n",
      "sub#2: Google\n"
     ]
    }
   ],
   "source": [
    "text = '<a href=\"http://www.google.com\" alt=\"google\">Google</a>'\n",
    "pat = re.compile(r'<a .*href=\"(\\S+?)\".*>(\\S+?)</a>')\n",
    "match = pat.fullmatch(text)\n",
    "print(f\"full: {match[0]:s}\")\n",
    "print(f\"sub#1: {match[1]:s}\")\n",
    "print(f\"sub#2: {match[2]:s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の例では、ハイパーリンクを定義したHTMLタグから、リンク先のURLとリンク文字列を抜き出している。この例で、`href=\"(\\S+.)\"`の部分でリンク先のURLを、`<a ...>(\\S+?)</a>`の部分でリンク文字列を、それぞれ取り出している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 名前付きサブグループ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "より複雑な例を扱う場合には、それぞれのサブグループに名前をつけることもできる。サブグループに名前をつけるには、サブグループを定義する括弧`(...)`の先頭に`(?P<name>...)`のように名前の定義を記述する。上記の例で各サブグループに名前をつけると以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full: <a href=\"http://www.google.com\" alt=\"google\">Google</a>\n",
      "url: http://www.google.com\n",
      "text: Google\n"
     ]
    }
   ],
   "source": [
    "text = '<a href=\"http://www.google.com\" alt=\"google\">Google</a>'\n",
    "pat = re.compile(r'<a .*href=\"(?P<url>\\S+?)\".*>(?P<text>\\S+?)</a>')\n",
    "match = pat.fullmatch(text)\n",
    "print(f\"full: {match[0]:s}\")\n",
    "print(f\"url: {match['url']:s}\")\n",
    "print(f\"text: {match['text']:s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、かなり複雑な例にはなるが、サブグループは階層的に定義することもできて、以下の例のように、HTMLタグの属性の書式が正しいかを調べることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full: <a href=\"http://www.google.com\" alt=\"google\">Google</a>\n"
     ]
    }
   ],
   "source": [
    "text = '<a href=\"http://www.google.com\" alt=\"google\">Google</a>'\n",
    "pat = re.compile(\n",
    "    r'<a(\\s*(?P<field>\\S+?)=\"(?P<value>\\S+?)\")*>(?P<text>.+?)</a>')\n",
    "match = pat.fullmatch(text)\n",
    "print(f\"full: {match[0]:s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、サブグループはマッチした最後の文字列を取り出すため、上記の例では`href=\"...\"`の部分を取り出すことはできず、名前付きサブグループで該当する文字列を取り出すと、`alt=\"...\"`の部分だけが取り出される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field': 'alt', 'value': 'google', 'text': 'Google'}\n"
     ]
    }
   ],
   "source": [
    "print(match.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字列の置き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サブグループは、文字列の置き換えにおいても強力なツールである。例えば、英語から日本語の書き換えの際に、`Section 1`という文字列を`第1節`のように書き換えたいとする。\n",
    "\n",
    "この場合、`Section 1`に対応する正規表現は`[Ss]ection\\s*?([0-9]+)`のような書式になる。この正規表現パターンに対して`sub`関数を用いて文字列の置き換えを行う場合、マッチしたサブグループは`\\1`のように**バックスラッシュ+数字**のような形で参照できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 1 -> 第1節\n",
      "section99 -> 第9節9\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(r\"[Ss]ection\\s*?([0-9]+?)\")\n",
    "print(text := \"Section 1\", \"->\", pat.sub(r\"第\\1節\", text))\n",
    "print(text := \"section99\", \"->\", pat.sub(r\"第\\1節\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "名前付きサブグループを使う場合には、`\\g<name>`のように書いてサブグループの名前を指定できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section  123 -> 第123節\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(r\"[Ss]ection\\s*?(?P<index>[0-9]+)\")\n",
    "print(text := \"section  123\", \"->\", pat.sub(r\"第\\g<index>節\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} サブグループ\n",
    ":class: note\n",
    "\n",
    "- 正規表現の中で `(...)`のように書くことでサブグループを定義できる\n",
    "- サブグループ内の正規表現にマッチした文字列は`match[1]`のような形で取り出せる\n",
    "- サブグループには`(?P<name>...)`のような形で名前をつけることもできる\n",
    "- サブグループにマッチした文字列は`\\1`や`\\g<name>`のような形で文字列の置き換えにも利用できる\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日本語の取り扱い\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結論から言うと、**日本語を取り扱うために意識しなければならないことはほとんどない**。例えば、とある日本語の文章に「こ」から始まり「は」で終わる5文字の言葉が含まれているかどうかを知りたいとする。\n",
    "\n",
    "ここまでの復習的な内容だが、「こ」や「は」が日本語の文字であるということを特別視しなければ、上記の条件に合う正規表現を導くことは容易だろう。正解は以下のようになる (初期状態ではセルを非表示にしてある)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こんにちは', 'こんばんは']\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(r\"こ.{3}は\")\n",
    "text = \"こんにちは こんばんわ こんばんは\"\n",
    "matches = pat.findall(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、日本語と英語が混じった文章もあるかもしれない。次のような場合はどうだろうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こんにちは', 'こ、AIは']\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(r\"こ.{3}は\")\n",
    "text = \"こんにちは。あのこ、AIは得意だって。\"\n",
    "matches = pat.findall(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もちろん、上記のような動作を想定して正規表現を使っているかもしれないが、日本語だけ、もっというとひらがなだけで構成された「こ」で始まり、「は」で終わる5文字の言葉を探したいかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実は、日本語のひらがなやカタカナは、Unicodeによって整理されており、これを用いると、英数字なのか平仮名なのか、といった文字種を判別することができる。Unicode上のひらがなは小文字の「ぁ」(`0x3041`)から「ゔ」(`0x3094`)までに定義されていて、一覧にすると以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ぁあぃいぅうぇえぉお\n",
      "かがきぎくぐけげこご\n",
      "さざしじすずせぜそぞ\n",
      "ただちぢっつづてでと\n",
      "どなにぬねのはばぱひ\n",
      "びぴふぶぷへべぺほぼ\n",
      "ぽまみむめもゃやゅゆ\n",
      "ょよらりるれろゎわゐ\n",
      "ゑをんゔ"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(range(0x3041, 0x3094 + 1)):\n",
    "    print(chr(c), end=\"\")\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じようにカタカナは「ァ」(`0x30A1`)から「ヴ」(`0x30F4`)までに定義されており、一覧にすると以下のようになる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ァアィイゥウェエォオ\n",
      "カガキギクグケゲコゴ\n",
      "サザシジスズセゼソゾ\n",
      "タダチヂッツヅテデト\n",
      "ドナニヌネノハバパヒ\n",
      "ビピフブプヘベペホボ\n",
      "ポマミムメモャヤュユ\n",
      "ョヨラリルレロヮワヰ\n",
      "ヱヲンヴ"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(range(0x30A1, 0x30F4 + 1)):\n",
    "    print(chr(c), end=\"\")\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicodeを用いると、ひらがな全体を表す文字クラスは`[\\u3041-\\u3094]`のように表すことができる。先ほどまでは16進数であることを表すために`0x`という接頭辞を用いていたが、正規表現中では代わりに`\\u`という接頭辞を使う。\n",
    "\n",
    "この例では、文字クラスが、ある意味で**数値の範囲**として表されているわけだが、ここで何か気がつくことはあるだろうか。実は、`[A-Z]`のような文字クラスも`A`や`Z`などを符号付き8bit整数としてUnicodeの範囲を示す数字として扱っていたに過ぎないのである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでを踏まえると、Unicodeを用いれば、「こ」で始まり「は」で始まるひらがな5文字の言葉を探す正規表現は以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こんにちは']\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(r\"こ[\\u3041-\\u3094]{3}は\")\n",
    "text = \"こんにちは。あのこ、AIは得意だって。\"\n",
    "matches = pat.findall(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この際、Pythonの文字列は**そもそもとして文字列中の各文字をUnicodeで扱っている**ので、ひらがなやカタカナそれ自体を文字セットの下限と上限を指定するのに用いても問題ない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こんにちは']\n"
     ]
    }
   ],
   "source": [
    "pat = re.compile(r\"こ[ぁ-ゔ]{3}は\")\n",
    "text = \"こんにちは。あのこ、AIは得意だって。\"\n",
    "matches = pat.findall(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、一般的な漢字は「一」(`0x4E00`)から「鿿」(`0x9FFF`)の範囲にある約2万文字がCJK統合漢字としてまとめられている。従って、日本語に使われうる文字を全て検出するには、`[\\u3041-\\u3094\\u30A1-\\u30F4\\u4E00-\\u9FFF]`のような文字クラスを用いれば良い。\n",
    "\n",
    "しかし、このような日本語文字のUnicodeや文字の範囲を覚えるのはなかなか大変である。実は、Pythonの`re`と互換性のあるサードバーティ製のライブラリに`regex`があり、このライブラリを用いると、ひらがな、カタカナ、漢字を含む文字クラスはそれぞれ以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "hira = regex.compile(r\"\\p{Hiragana}\")\n",
    "kata = regex.compile(r\"\\p{Katakana}\")\n",
    "kanji = regex.compile(r\"\\p{Han}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に`regex`ライブラリを用いて、上記の「こ、から始まり、は、で終わる5文字の単語」を取り出してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こんにちは']\n"
     ]
    }
   ],
   "source": [
    "pat = regex.compile(r\"こ\\p{Hiragana}{3}は\")\n",
    "text = \"こんにちは。あのこ、AIは得意だって。\"\n",
    "matches = pat.findall(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらのライブラリはサードパーティ製なので、別途インストールが必要ではあるものの、Unicodeの範囲を指定するよりは、表記も分かりやすいだろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 日本語の取り扱い\n",
    ":class: note\n",
    "\n",
    "- Pythonでは日本語を扱うために特別意識することはない\n",
    "- ただし、ひらがなだけ、カタカナだけ、といった場合を扱うには文字クラスの定義が必要\n",
    "- 日本語を扱う文字クラスはUnicodeで範囲を指定して定義する\n",
    "- サードパーティ製の`regex`ライブラリを用いると簡単に文字クラスが定義できる。\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "## 練習問題\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{card}\n",
    "**問1**\n",
    "^^^\n",
    "正規表現を用いて、HTML タグから、タグ名、id、class の情報を取り出す関数を作成せよ。その際、id と class の指定順序は順不同であるほか、それ以外の属性値 (`align=\"center\"`など)が指定されている場合もあることに注意せよ。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 問1\n",
    "def Q1(text: str):\n",
    "    pat = re.compile(\"<(?P<tag>[a-z]+?)\\s+?(?P<fields>.+)>\")\n",
    "    match = pat.search(text)\n",
    "    tag = match[\"tag\"]\n",
    "    fields = match[\"fields\"]\n",
    "\n",
    "    pat = re.compile('(?P<key>\\S+?)=\"(?P<value>\\S+?)\"')\n",
    "    matches = pat.findall(fields)\n",
    "    fields = {k: v for k, v in matches}\n",
    "\n",
    "    id = None\n",
    "    if \"id\" in fields:\n",
    "        id = fields[\"id\"]\n",
    "    cls = None\n",
    "    if \"class\" in fields:\n",
    "        cls = fields[\"class\"]\n",
    "\n",
    "    return tag, id, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div id=\"container\" class=\"main\">'"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "input1-1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('div', 'container', 'main')"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "output1-1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = '<div id=\"container\" class=\"main\">'\n",
    "output = Q1(input)\n",
    "glue(\"input1-1\", input)\n",
    "glue(\"output1-1\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "* **入力例1:** {glue:text}`input1-1`\n",
    "* **出力例1:** {glue:text}`output1-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"form\" align=\"center\">'"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "input1-2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('div', None, 'form')"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "output1-2"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = '<div class=\"form\" align=\"center\">'\n",
    "output = Q1(input)\n",
    "glue(\"input1-2\", input)\n",
    "glue(\"output1-2\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **入力例2:** {glue:text}`input1-2`\n",
    "* **出力例2:** {glue:text}`output1-2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{card}\n",
    "**問2**\n",
    "^^^\n",
    "日本語の文章が与えられたとき、漢字の四字熟語だけを正規表現を用いて取り出す関数を作成せよ。この際、四字より多い感じから構成される熟語 (例: 日常茶飯事、日々是好日)を取り出さないようにすること。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def Q2(text):\n",
    "    pat = re.compile(\"[\\u4E00-\\u9FFF]{4,}\")\n",
    "    matches = pat.findall(text)\n",
    "    matches = [m for m in matches if len(m) == 4]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'だんだんと暖かくなってきました。これが三寒四温ですね。'"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "input2-1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['三寒四温']"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "output2-1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = \"だんだんと暖かくなってきました。これが三寒四温ですね。\"\n",
    "output = Q2(input)\n",
    "glue(\"input2-1\", input)\n",
    "glue(\"output2-1\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **入力例1:** {glue:}`input2-1`\n",
    "* **出力例1:** {glue:}`output2-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'彼の遅刻は日常茶飯事です。'"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "input2-2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "output2-2"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = \"彼の遅刻は日常茶飯事です。\"\n",
    "output = Q2(input)\n",
    "glue(\"input2-2\", input)\n",
    "glue(\"output2-2\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* **入力例2:** {glue:}`input2-2`\n",
    "* **出力例2:** {glue:}`output2-2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
